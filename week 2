SELECT 
	o.product_id,
	r.reason_returned
FROM returns AS r
LEFT JOIN orders AS o
	ON o.order_id = r.order_id
WHERE r.reason_returned = 'Not Given'
-- if you swap orders and returns, you can get the same result using 'right join'. You need to know what you are looking for (here product info on ALL returns)

-- Except below; what's it doing?
SELECT product_id, product_name
FROM products
WHERE category = 'Furniture'
EXCEPT
SELECT product_id, customer_id
FROM orders
WHERE DATE_PART('year', order_date) = '2020';
-- NOTE: the product_name and customer_id are both text fields so this works BUT these columns are different SO we actually get all rows returned

SELECT product_id FROM products WHERE category = 'Furniture'
EXCEPT
SELECT product_id FROM orders WHERE DATE_PART('year', order_date) = '2020';
-- whereas here, we remove product_name and customer_id, and we are subtracting the second query from the first on product_id column
-- the second table - the first table based on the product_id's in both tables. The except gives us all the ones that don't match. 
-- This gives us: furniture that was NOT sold in 2020.

SELECT a.product_id, b.reason_returned
FROM orders AS a
LEFT JOIN returns AS b
USING(order_id)
WHERE b.reason_returned is NULL
-- All orders returned then matching order_id's from returns added. We then filter using where nulls on a column from returns to only show NULLS. Meaning we get the pacman venn
-- This is like an exception because the Nulls after the join are being shown

SELECT reg.salesperson, COUNT(o.sales) AS num_sales
FROM orders as o
INNER JOIN regions as reg
ON reg.region_id = o.region_id
-- we want regions added to orders because it will show us all the orders by people. Why? because regions table has a salesperson
LEFT JOIN returns as ret
ON o.order_id = ret.order_id
-- here we want all the orders, whether or not they were returned so we use LEFT JOIN
WHERE ret.order_id IS NULL
-- the where IS NULL turns the left join into a PACMAN
GROUP BY reg.salesperson
ORDER BY num_sales DESC

SELECT
  product_id, 
  quantity/NULLIF(discount,0) AS discount_per_item
FROM orders
WHERE ship_mode = 'Standard Class';
-- use NULLIF where you need to divide by a column and there might be a 0 present. It will change it to a NULL

-- OR this is the same, but using CASE
SELECT product_id, 
	CASE 
		WHEN discount = 0 THEN NULL
		WHEN discount > 0 THEN quantity/discount 
		END AS discount_per_item
FROM orders
WHERE ship_mode = 'Standard Class';

SELECT order_id, product_id, sales, 
COALESCE(postal_code, 'carol') 
AS coalesced FROM orders;
-- this replaces nulls in postal_code with 'carol'

SELECT order_date, DATE_PART('Year', order_date)
FROM orders
-- extracts the year part from a timestamp, can also do with month etc, check postgres documentation

SELECT order_date, DATE_PART('Year', order_date) = 2020
FROM orders
WHERE DATE_PART('Year', order_date) = 2020
-- This will give the Boolean operation, checking if 2020 is present in the timestamp and returning T/F

SELECT DISTINCT customers.customer_id, customer_name, segment
FROM customers
LEFT JOIN orders
	using(customer_id)
WHERE DATE_PART('year', order_date) = 2020

-- Independent practice (Day 1 week 2)

-- Q1
SELECT order_id
FROM orders
	INNER JOIN customers
	USING(customer_id)
WHERE segment = 'Consumer'
LIMIT 1000

-- Q2
SELECT order_id, product_name
FROM products
	INNER JOIN orders
	USING(product_id)
WHERE product_name ILIKE '%Photo Frame%'

-- Q3
SELECT product_name 
FROM products
LEFT JOIN orders
USING(product_id)
WHERE product_name ILIKE '%Photo Frame%' AND order_id IS NULL
-- answer is no rows

-- Q4
SELECT DISTINCT(product_id), country
FROM orders
LEFT OUTER JOIN regions 
USING(region_id)
WHERE country ILIKE '%France%'
-- answer is 9412 products

--Q4 answer 2
SELECT DISTINCT product_name, country
FROM products
INNER JOIN orders
USING(product_id)
INNER JOIN regions
USING(region_id)
WHERE country ILIKE '%France%'
-- 3587 - also correct but on distinct product_name not product_id

-- Q5 
SELECT DISTINCT product_id, country
FROM orders
INNER JOIN products
USING(product_id)
INNER JOIN regions
USING(region_id)
WHERE country ILIKE '%United States%' and product_name ILIKE '%Recycled%' 
-- 403 rows

-- Q5 answer 2
SELECT DISTINCT product_name, country
FROM orders
INNER JOIN regions
USING(region_id)
INNER JOIN products
USING(product_id)
WHERE country ILIKE '%United States%' and product_name ILIKE '%Recycled%' 
-- 118 rows

-- Q6 
SELECT DISTINCT product_id
FROM orders
INNER JOIN regions
USING(region_id)
INNER JOIN products
USING(product_id)
WHERE product_name NOT ILIKE '%Photo Frame%' AND country ILIKE '%Canada%'
--4671 result (not the same as given answer of 79)

--Q7
SELECT product_name from products
EXCEPT
SELECT order_id FROM orders

--Q8 
SELECT region_id FROM orders
EXCEPT
SELECT region_id FROM regions

SELECT SUM(sales), AVG(sales), DATE_PART('year', order_date) AS order_year 
FROM orders
GROUP BY order_year

SELECT salesperson, DATE_PART('month', order_date)
FROM orders
INNER JOIN regions
USING(region_id)

SELECT COUNT(order_id), ship_mode
FROM orders
INNER JOIN returns
USING(order_id)
WHERE reason_returned IN ('Wrong Item')
GROUP BY ship_mode

-- OR use a subquery like below to get same result
SELECT ship_mode, COUNT( * )
FROM Orders
WHERE order_id IN (
 SELECT order_id FROM returns
 WHERE reason_returned = 
'Wrong Item' 
 ) 
GROUP BY ship_mode;

SELECT customer_type, SUM(total_sales) AS total_sales
FROM
(SELECT customer_id,
	CASE
		WHEN COUNT(DISTINCT order_id) >= 1000 THEN 'Supplier'
		WHEN COUNT(DISTINCT order_id) >= 100 AND COUNT(DISTINCT order_id) < 1000 THEN 'Multiple'
		ELSE 'ALL Others'
		END AS customer_type,
		SUM(sales) AS total_sales
FROM orders
GROUP BY customer_id)
AS temp
GROUP BY customer_type
ORDER BY total_sales
-- the inner query returns an output temporary table (using case to categorise the counts of customers). We then select and group by those columns in the outer query 

SELECT COUNT(*)
FROM orders
WHERE product_id IN (
SELECT product_id 
 	 FROM products 
 WHERE CAST(product_cost_to_consumer AS int) > 500);
-- with IN clause we don't need an ALIAS

-- This query gives same result but using NOT IN and changing the comparison operator
SELECT COUNT(*)
FROM orders
WHERE product_id NOT IN (
SELECT product_id 
 	 FROM products 
 WHERE CAST(product_cost_to_consumer AS int) <= 500);

SELECT COUNT(*)
FROM orders
WHERE product_id IN (
SELECT product_id 
 	 FROM products 
 WHERE CAST(product_cost_to_consumer AS int) > 500);
-- with WHERE __ IN clause we don't need ALIAS

SELECT COUNT(*)
FROM orders
WHERE CAST(profit AS int) >
(SELECT AVG(CAST(product_cost_to_consumer AS int))
 FROM products)
-- we use CAST to change floats to ints so we get a whole number avg, Here the sub-query returns the avg product cost as int

SELECT customer_type, SUM(total_sales)/(SELECT SUM(sales) FROM orders) AS total_sales
FROM
(SELECT customer_id,
	CASE 
 		WHEN COUNT(DISTINCT order_id)>=1000 THEN 'Supplier'
		WHEN COUNT(DISTINCT order_id)>=100 THEN 'Frequent'
		ELSE 'All others' 
 		END as customer_type,
	SUM(sales) as total_sales
FROM orders
GROUP BY 1) AS temp
GROUP BY 1
ORDER BY 2 DESC;
-- Remember, sub query is giving the sum of sales for each of the categories (we have defined). 
-- This one takes each category total and divides by the sum of all sales to give a % or each category 

SELECT 	profit_size, 
		COUNT(*) AS number_orders 
FROM 
	(SELECT order_id, profit, 
	CASE
		WHEN CAST(profit AS int) >= 1000 THEN 'large'
		WHEN CAST(profit AS int) >= 50 THEN 'medium'
		ELSE 'small'
		END AS profit_size 
		FROM orders) 
	AS temp
GROUP BY profit_size

SELECT product_id, ROUND(AVG(over_25), 4) AS pct_over_25
FROM (SELECT product_id, profit,
CASE WHEN CAST(discount AS float) > 0.25 THEN 1
ELSE 0
END AS over_25
FROM orders) AS temp
GROUP BY product_id
ORDER BY product_id
LIMIT 100;
-- We can categorise by 1 and 0, then take the average of these 1, 0s to see % of products that have discount over 0.25 

WITH 
	cte_tab1 (product_id, over_25) 
	AS 
	(SELECT product_id,
		CASE
			WHEN CAST(discount AS float) > 0.25 THEN 1
			ELSE 0
			END AS over_25
		FROM orders)

SELECT product_id, ROUND(AVG(over_25), 4) AS pct_over_25
FROM cte_tab1
GROUP BY product_id
ORDER BY product_id
LIMIT 100;
-- we can use CTE's to create a temp table instead of always writing our a sub-query
-- This gives same result as above

-- A more complex example, but see that three temp tables are being created t1_cte, t2_cte, t3_cte
WITH 
 t1_cte (order_year, quantity, discount, product_id, customer_id) AS ( 
  SELECT EXTRACT(YEAR FROM order_date) AS order_year, quantity, 
  discount, product_id, customer_id FROM orders),
 t2_cte (product_description, product_cost_to_consumer, product_id) AS (
  SELECT (sub_category || ', ' || product_name) AS product_description, 
  product_cost_to_consumer, product_id FROM products),
 t3_cte (customer_description, customer_id) AS (
  SELECT (segment || ': ' || customer_name) AS customer_description, 
  customer_id FROM customers)
 -- These CTE's are temporary tables, the first columns names are defined by the select statement after the 'AS' 
 
SELECT customer_description, product_description, order_year, 
 (CAST(quantity AS INTEGER) * CAST(product_cost_to_consumer AS INTEGER) 
  * (1 - CAST(discount AS NUMERIC))) AS estimated_profit 
FROM t1_cte AS t1
INNER JOIN t2_cte AS t2 ON t1.product_id = t2.product_id
INNER JOIN t3_cte AS t3 ON t1.customer_id = t3.customer_id 
WHERE (CAST(quantity AS INTEGER) * CAST(product_cost_to_consumer AS INTEGER) 
  * (1 - CAST(discount AS NUMERIC))) < 100

-- Now we have defined our temp tables to use (t1_cte etc), we can more simply use those 'shortcut' tables in our SELECT query
-- i.e. we don't have to know the details of new defined temp tables,we simply use a CTE shortcut 

SELECT sales, sales * 2 AS lets_report_double_and_get_a_bonus
FROM orders
LIMIT 10
-- arithmetic operator 

SELECT sales, sales > 20
FROM orders
LIMIT 10
-- relational operator (giving T/F/unknown) Boolean

SELECT sales, sales BETWEEN 70 AND 80 AS more_than
FROM orders
LIMIT 10
-- Logical operator

SELECT SUM(sales) + SUM(profit) +5 AS calc_weird
FROM orders
-- sometimes you can't sum columns directly, here we use aggregate function on a column and add then separately

SELECT ROUND(sales, 1) AS rounded_sales, sales
FROM orders
WHERE ROUND(sales, 1) = 78.4
-- Can round the sales to 1 (or any) decimal point here, can then use a where to filter on that rounded column

SELECT sales, 5, 5/2, 5.0/2.0, 5.0/2, 5/2.0
FROM orders
LIMIT 10
-- note data type important in calcs

SELECT sales, CAST(sales AS int) AS int_sales, CAST(SUM(sales) AS int)
FROM orders
GROUP BY sales, int_sales
-- CAST changes data type, need parameters --> the column AS the new type

SELECT sales, sales::integer, CAST(sales AS int) AS int_sales, CAST(SUM(sales) AS int)
FROM orders
GROUP BY sales, int_sales
-- can use shorthand :: for cast
-- NOTE CAST is different accross DBs - using :: may trunc or cast/round etc, so need to check if important

SELECT return_quantity, return_quantity::numeric AS returns_as_num, ROUND(CAST(return_quantity AS numeric)+3.7,0) AS bonus_returns
FROM returns
-- can do different things with CAST, here the 3rd column is numeric type but rounded as a whole number (i.e. not int)


-- TEXT strings
SELECT customer_name, CONCAT(segment, '_', customer_name)
FROM customers
-- join text's together 

SELECT customer_name, LENGTH(customer_name)
FROM customers
-- get length of string (number characters including spaces)

SELECT customer_name, REPLACE(customer_name, 'Allen', 'Alan') AS new_cust_name
FROM customers
-- replace Allen with Alan

SELECT customer_name, UPPER(customer_name), LOWER(customer_name)
FROM customers
-- change case of text string

SELECT customer_name 
FROM customers
WHERE LOWER(customer_name) like '%alex%'
-- use this if no ILIKE (ILIKE only in Postgres) to search without case sensitive 

SELECT SUBSTRING(customer_id, 4, 20) AS extract_id, customer_id
FROM customers
-- starting from first index (4) and giving number of chars (20)

SELECT SUBSTRING(customer_id, 4, 20)::int AS extract_id, customer_id
FROM customers
-- use substring to do same, but change to numeric --> can now do maths!

SELECT customer_name,
	LEFT(customer_name, 2) AS first_2_char, -- start reading from the left, 2 char
	RIGHT(customer_name, 3) AS last_3_char -- start reading from the right, 3 char
FROM customers
-- get first or last chars

SELECT customer_name,
	LEFT(customer_name, 2) AS first_2_char, -- start reading from the left, 2 char
	RIGHT(customer_name, 3) AS last_3_char -- start reading from the right, 3 char
FROM customers
WHERE LOWER(LEFT(customer_id, 3)) like 'aa-%'  
-- or add as a lovely filter for id's starting with ___

SELECT customer_name, TRIM(leading 'AA' FROM customer_id)
FROM customers
-- This removes the 'AA' from the beginning of the id (can also use 'trailing' for end, and 'both' from both ends)
-- Trim also used to remove spaces (only from ends)

SELECT customer_name, STRPOS('Andrew', 'drew')
FROM customers
WHERE customer_name LIKE '%Andrew%'
-- STRPOS gives us the start position of 'drew' in 'Andrew' 

SELECT customer_name, STRPOS('Andrew', customer_name),
		substring(customer_name, STRPOS('Andrew', customer_name), 20)		
FROM customers
WHERE customer_name LIKE '%Andrew%'
-- Here we find out where 'Andrew' starts in customer_name
-- Can use this within a substring to extract based on a start position

SELECT order_id, REVERSE(order_id)
FROM orders
LIMIT 50
-- reverse the string, often used as a way to quickly de-identify but keep id information (just reversed)

-- Independent practice
-- Q1 
-- count or orders returned in 2019 by country. Limit to top 5 by count of returns. Include avg profit for returned orders

SELECT country, COUNT(orders.order_id) AS count_orders
FROM orders
INNER JOIN returns 
USING(order_id)
INNER JOIN regions
USING(region_id)
WHERE order_id IN(SELECT order_id FROM returns
				 WHERE DATE_PART('year',return_date)='2019')
GROUP BY country
ORDER BY count_orders DESC
LIMIT 5

--Q2
SELECT 
	product_id, product_freq
FROM
	(SELECT 
		CASE
	 	WHEN COUNT(product_id) BETWEEN 150 AND 1000 THEN 'high'
	 	WHEN COUNT(product_id) BETWEEN 150 AND 50 THEN 'medium'
	 	WHEN COUNT(product_id) BETWEEN 5 AND 0 THEN 'very low'
	 	ELSE 'other'
	 	END AS product_freq
	 	FROM orders
		) AS temp
	
FROM products
INNER JOIN orders
USING(product_id)
GROUP BY 
ORDER BY 

-- DATE FUNCTIONS
SELECT CURRENT_DATE
SELECT CURRENT_TIME

SELECT order_date, CURRENT_DATE, (CURRENT_DATE-order_date) AS time_to_current
FROM orders
-- NOTE: the current_date is the system date i.e. here the date of the server NOT my time

SELECT TO_DATE
-- converts text string to date according to the format you give

SELECT order_date, TO_DATE('05 DEC 2000', 'DD Mon YYYY'), '2000-12-05'::date
FROM orders
LIMIT 10
-- some different ways to change text string to date type
SELECT order_date, TO_DATE('05 DECEMBER 2000', 'DD Month YYYY'), '2000-12-05'::date
FROM orders
LIMIT 10

SELECT AGE(order_date)
FROM orders

SELECT AGE('2017-01-01', '2011-06-24')
-- here we aren't calling a traditional FROM table - but we give two data points

SELECT order_date, ship_date, AGE(ship_date, order_date) AS days_to_ship
FROM orders
LIMIT 10

SELECT DATE_PART('year', order_date), DATE_PART('century', order_date)
FROM orders

SELECT TO_CHAR(order_date, 'HH:MI:SS')
FROM orders
SELECT TO_CHAR(order_date, 'D')
FROM orders
-- date to string (may be useful if creating a CSV for excel)
-- also not just for dates

SELECT EXTRACT(hour FROM order_date)
FROM orders
SELECT EXTRACT(year FROM order_date)
FROM orders
SELECT EXTRACT(day FROM order_date)
FROM orders
-- extract the given timestamp subfield, hour, year etc)
-- DATE_PART is the same as EXTRACT, but DATE_PART common in postgres

SELECT DATE_TRUNC('month', order_date)
FROM orders
-- truncates the timestamp at specified precision, 'hour', 'year' etc

SELECT order_date, ship_date
FROM orders

SELECT ship_date - order_date AS time_order_to_ship
FROM orders

-- CTE example below

-- SELECT 
-- 	ROUND(SUM(sales),0) AS total_sales, 
-- 	AVG(sales)::INT AS avg_sales, 
-- 	ROUND(MAX(sales),0) AS max_sale, 
-- 	COUNT(sales) AS count_sales, 
-- 	customer_id,
-- 	order_date
-- FROM orders
-- WHERE DATE_PART('month', order_date) = 12
-- GROUP BY customer_id, order_date
-- ORDER BY total_sales DESC

-- SELECT 
-- 	ROUND(SUM(sales), 0) AS total_sales, 
-- 	AVG(sales)::INT AS avg_sales, 
-- 	MAX(sales) AS max_sales, 
-- 	COUNT(sales) AS count_sales, 
-- 	customer_id
-- 	FROM orders
-- 	GROUP BY customer_id
-- 	ORDER BY total_sales DESC

-- SELECT UPPER(customer_id), UPPER(customer_name) FROM customers

-- select
-- 	customer_id, order_date,
-- 	sum(sales) as total_sales,
-- 	avg(sales)::int as avg_sales,
-- 	max(sales) as max_sales,
-- 	count(sales) as count_sales
-- 	from orders
-- 	where extract('month' from order_date) = 12
-- 	group by customer_id,order_date
-- 	order by total_sales desc

-- commented out original queries above

WITH
t1_cte (total_sales, avg_sales, max_sales, count_sales, customer_id) AS (SELECT 
	ROUND(SUM(sales), 0) AS total_sales, 
	AVG(sales)::INT AS avg_sales, 
	MAX(sales) AS max_sales, 
	COUNT(sales) AS count_sales, 
	customer_id
	FROM orders
	GROUP BY customer_id
	ORDER BY total_sales DESC),

upper_cust (upper_cust_id, upper_cust_name) AS (SELECT UPPER(customer_id), UPPER(customer_name) FROM customers),

sales_dec_data (customer_id, order_date, total_sales, avg_sales, max_sales, count_sales) AS 
	(select
	customer_id, order_date,
	sum(sales) as total_sales,
	avg(sales)::int as avg_sales,
	max(sales) as max_sales,
	count(sales) as count_sales
	from orders
	where extract('month' from order_date) = 12
	group by customer_id,order_date
	order by total_sales desc)

SELECT upper_cust_name, total_sales, avg_sales, max_sales
FROM upper_cust
INNER JOIN sales_dec_data
ON upper_cust.upper_cust_id = sales_dec_data.customer_id

-- NOTE:we've created queries and (temp) saved them as CTE tables. We can query them for another SELECT
-- The join is ON different column names, if customer_id was in both tables we could use USING with common name
-- HERE we have aggregated data in one CTE (in count, max etc) and we join it with non-aggregated data (cust_name) in table 2 CTE 

-- WITH DB BROWSER 
WITH
emp (employee_id, employee_name, manager_id, department_name) AS (SELECT * FROM employees),
emp_count (department_name, emp_department) AS (SELECT department_name, COUNT(employee_id) AS emp_department FROM employees GROUP BY department_name)

SELECT * FROM emp 
JOIN emp_count
USING(department_name)
-- we display table 2 with department_name and use THIS to join the tables, not employee_id)

select *,
			 count(*) over ( PARTITION BY  department_name) as by_department,
			 count(*) over () as all_emp,
			 sum(employee_id) over () as emp
			 sum(employee_id) over (PARTITION BY department_name) as emp_pay_depart
from employees			 
-- can use partitions as window functions. This shows you an aggregate value but also with the detail of individual rows (not possible by other techniques)

-- WINDOW FUNCTION
SELECT 
	region_id, 
	sum(sales) OVER (PARTITION BY region_id
) AS sum_of_sales
FROM orders;
-- partition shows the aggregate of total sales per region, but keeps each instance info

--compare this to our regular query 
SELECT 
		region_id, 
		SUM(sales) AS sum_of_sales
FROM orders
GROUP BY region_id;
-- this is our only option without partition, we have to group by region_id because we have agg in select
-- we can't see all individual info AND aggregate for a group

-- OR this, we group by two columns
SELECT 
		region_id,
		order_id,
		SUM(sales) AS sum_of_sales
FROM orders
GROUP BY order_id, region_id
ORDER BY region_id;
-- BUT this shows the sum of sales for each combination or region_id and order_id so not what we want

SELECT sub_category
, product_name
, product_cost_to_consumer,
ROW_NUMBER() OVER (
PARTITION BY sub_category ORDER BY
product_cost_to_consumer DESC
)
FROM products
-- Need order by so that the row_number means something --> we can get the top (or bottom) rows for our desired column

SELECT sub_category
, product_name
, product_cost_to_consumer,
RANK() OVER (
PARTITION BY sub_category ORDER BY
product_cost_to_consumer DESC
)
FROM products;
-- Columns are partitioned by sub_cat (e.g. access) then ordered by price, then it is ranked. Same price means equal rank.
-- This Rank restarts rank count inclusive of rows, i.e. 11345, not 112345 (we use Dense Rank for this)

SELECT sub_category
, product_name
, product_cost_to_consumer,
DENSE_RANK() OVER (
PARTITION BY sub_category ORDER BY
product_cost_to_consumer DESC
)
FROM products;
-- This is Dense Rank exclusive or rows i.e. 112345 NOT 11345 - It doesn't skip numbers in the dense rank.

WITH daily_quantity AS (
    SELECT order_date
    , SUM(quantity) AS total_quantity
    FROM orders
    WHERE date_part('year', order_date) = 2019
    GROUP BY order_date
    ORDER BY order_date
)
SELECT order_date
, total_quantity
, LAG(total_quantity, 1) OVER (
    ORDER BY order_date
) AS total_quantity_lag1
FROM daily_quantity;
-- gives us the same result in a new column, but for the x days, change the number in lag 

WITH daily_quantity AS (
SELECT order_date
, SUM(quantity) AS total_quantity
FROM orders
WHERE date_part('year', order_date) = 2019
GROUP BY order_date
ORDER BY order_date
)
SELECT order_date
, total_quantity
, LEAD(total_quantity, 1) OVER (
ORDER BY order_date
) AS total_quantity_lag1
FROM daily_quantity;
-- lead is opposite of lag
